{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61db0c2d",
   "metadata": {},
   "source": [
    "### 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e182403",
   "metadata": {},
   "source": [
    "GloVe는 대상 단어에 대하여 코퍼스에 함께 나타난 단어별 출현 빈도를 예측하도록 합니다.\n",
    "\n",
    "<br></br>\n",
    "$$\\hat{\\theta} = argmin_{\\theta} \\sum_{x \\in X} f(x)|W'Wx-logC_x|_2^2 \\\\\n",
    "\\text{where $C_x$ is vector of cooccurences with x} \\\\\n",
    "\\text{Also, $x \\in \\{0,1\\}^{|V|}, W \\in R^{dx|V|} and W' \\in R^{|V|xd}$}$$\n",
    "<br></br>\n",
    "\n",
    "이를 살펴보면 skip-gram을 위한 네트워크와 거의 유사한 형태임을 알 수 있습니다. 다만 여기서는 분류 문제가 아닌, 출현 빈도를 근사하는 회귀 문제가 되었기에 평균제곱오차 (MSE)를 사용한 것을 볼 수 있습니다.\n",
    "\n",
    "마찬가지로 원핫 인코딩 벡터 x를 입력으로 받아 한개의 은닉층 W를 거쳐 출력층 W'를 통해 출력 벡터를 반환합니다. 이 출력 벡터는 단어 x와 함께 코퍼스에 출현했던 모든 단어의 각 동시 출현 빈도들을 나타낸 벡터인 $C_x$를 근사해야 합니다. 따라서 이 둘의 차이값인 소실을 최소화 하도록 역전파 및 경사하강법을 통해 학습할 수 있습니다.\n",
    "\n",
    "이때 단어 x 자체의 출현 빈도 또는 사전확률에 따라 MSE 손실 함수의 값의 크기가 매우 달라집니다. $C_x$ 값 자체가 클수록 손실 값은 커질 것이기 때문입니다. 따라서 f(x)라는 단어의 빈도에 따라 다음과 같이 손실 함수에 가중치를 부여합니다.\n",
    "\n",
    "<br></br>\n",
    "$$f(x) = \\begin{cases} (Count(x)/thres)^\\alpha & \\text{if $Count(x) < thres$} \\\\ 1 & \\text{otherwise} \\end{cases}$$\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3741df4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28562d1",
   "metadata": {},
   "source": [
    "### 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919eeca",
   "metadata": {},
   "source": [
    "코퍼스 냄에서 주변 단어를 예측하고자 하는 skip-gram과 달리, GloVe는 처음에 코퍼스를 통해 단어별 동시 출현 빈도를 조사하여 그에 대한 출현 빈도 행렬을 만들고, 이후엔 해당 행렬을 통해 동시 출현 빈도를 근사하려 합니다. 따라서 코퍼스 전체를 훑으며 대상 단어와 주변 단어를 가져와 학습하는 과정을 반복하는 skip-gram과 달리 훨씬 학습이 빠릅니다.\n",
    "\n",
    "또한 skip-gram의 특징상 사전확률이 낮은 (즉, 출현 빈도 자체가 적은) 단어에 대해서는 학습 기회가 적을 수 밖에 없습니다. 따라서 출현 빈도가 적은 단어들은 비교적 부정확한 단어 임베딩 벡터를 학습하게 됩니다. 하지만 GloVe는 이러한 단점이 보완되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d23059",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

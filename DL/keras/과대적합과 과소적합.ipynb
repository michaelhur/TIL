{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0380c550",
   "metadata": {},
   "source": [
    "머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기입니다. **최적화 (optimization)**은 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정입니다. 반면 **일반화 (generalization)**는 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미합니다. 모델을 만드는 목적은 좋은 일반화 성능을 얻는 것입니다. 하지만 일반화 성능을 제어할 방법은 없고 단진 훈련 데이터를 기반으로 모델을 조정하는 수만 있습니다.\n",
    "\n",
    "훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실도 낮아집니다. 이런 상황이 발생했을때 모델이 **과소적합 (underfitting)**되었다고 말합니다. 모델의 성능이 계속 발전될 여지가 있습니다. 네트워크가 훈련 데이터에 있는 관련 특성을 모두 학습하지 못한 상황입니다. 하지만 훈련 데이터에 여러번 반복 학습하고 나면 어느 시점부터 일반화 성능이 더 이상 높아지지 않습니다. 검증 세트의 성능이 멈추고 감소되기 시작합니다. 즉 모델이 **과대적합 (overfitting)**되기 시작합니다. 이는 훈련 데이터에 특화된 패턴을 학습하기 시작했다는 의미입니다.\n",
    "\n",
    "모델이 관련성이 없고 좋지 못한 패턴을 훈련 데이터에서 학습하지 못하도록 하려면 가장 좋은 방법은 더 많은 훈련 데이터를 모으는 것입니다. 더 많은 데이터에서 훈련된 모델은 자연히 일반화 성능이 더울 뛰어납니다. 더 많은 데이터를 모으는 것이 불가능할 때는 모델이 수용할 수 있는 정보의 양을 조절하거나 저장할 수 있는 정보에 제약을 가하는 것 입니다. 네트워크가 적은 수의 패턴만 기억할 수 있다면 최적화 과정에서 가장 중요한 패턴에 집중하게 될 것입니다.\n",
    "\n",
    "이런 식으로 과대적합을 피하는 처리 과정을 **규제 (regularization)**라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323ab09",
   "metadata": {},
   "source": [
    "### 네트워크 크기 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780afd3",
   "metadata": {},
   "source": [
    "과대적합을"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

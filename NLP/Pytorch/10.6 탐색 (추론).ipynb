{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1133dbf",
   "metadata": {},
   "source": [
    "이제까지 X와 Y가 모두 주어진 훈련상황을 가정했습니다. 이번에는 X만 주어진 상태에서 $\\hat{Y}$을 추론하는 방법에 관해 서술하겠습니다. 이러한 과정을 추론 또는 $탐색^{search}$라고 부릅니다. 결국 우리가 원하는 것은 단어들 사이에서 최고의 확률을 갖는 $경로^{path}$를 찾는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd349f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b44475",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efb2b7",
   "metadata": {},
   "source": [
    "먼저 떠올릴 수 있는 가장 정확한 방법은 각 time-step별 $\\hat{y_t}$을 고릴때 마지막 softmax 계층에서의 확률 분포대로 샘플링하는 것입니다. 그리고 다음 time-step에서 그 선택 $\\hat{y_t}$을 기반으로 다음 $\\hat{y_{t+1}}$을 도 다시 샘플링하여 최종적으로 EOS가 나올때까지 샘플링을 반복합니다. 이렇게 하면 우리가 원하는 분포에 가장 가까운 형태의 번역이 완성될 것입니다. \n",
    "\n",
    "하지만 이러한 방식은 같은 입력에 대해 매번 다른 출력 결과물을 만들어 낼 수 있습니다. 따라서 우리가 원하는 형태의 결과물은 아닙니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\hat{y_t} \\sim P(y_t|X,\\hat{y_{<t}};\\theta)\n",
    "$$\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c259e5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2fa6f",
   "metadata": {},
   "source": [
    "### Greedy Search Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fdddee",
   "metadata": {},
   "source": [
    "탐욕 탐색 알고리즘을 기반으로 탐색을 구현해보겠습니다. 즉, 소프트맥스 계층에서 가장 확률값이 큰 인덱스를 뽑아 해당 time-step의 $\\hat{y_t}$으로 사용하는 것입니다. 이를 수식으로 나타내면 다음과 같습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\hat{y_t} = argmax_{y \\in Y} P(y_t|X,\\hat{y_{<t}};\\theta)\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "![](./images/10-6-2-greedy.jpg)\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cdc08",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e134e07",
   "metadata": {},
   "source": [
    "### 파이토치 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a043c0b",
   "metadata": {},
   "source": [
    "다음은 Greedy Search Algorithm을 위한 코드입니다. 인코더가 동작하는 부분까지는 완전히 똑같습니다. 다만, 이후 추론을 위한 부분은 teacher forcing을 사용했던 훈련 방식과 달리, 실제 이전 time-step의 출력을 현재 time-step의 입력으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee438ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(self, src, is_greedy = True, max_length = 255):\n",
    "    mask, x_length = None, None\n",
    "    \n",
    "    if isinstance(src, tuple):\n",
    "        x, x_length = src\n",
    "        mask = self.generate_mask(x, x_length)\n",
    "        \n",
    "    else:\n",
    "        x = src\n",
    "        \n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    emb_src = self.emb_src(x)\n",
    "    h_src, h_0_tgt = self.encoder((emb_src, x_length))\n",
    "    h_0_tgt, c_0_tgt = h_0_tgt\n",
    "    h_0_tgt = h_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size).transpose(0,1).contiguous()\n",
    "    \n",
    "    c_0_tgt = c_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size).transpose(0,1).contiguous()\n",
    "    \n",
    "    h_0_tgt = (h_0_tgt, c_0_tgt)\n",
    "    \n",
    "    ## Fill a vector, which has \"batch_size\" dimension with BOS value.\n",
    "    y = x.new(batch_size, 1).zero_() + data_loader.BOS\n",
    "    is_undone = x.new_ones(batch_size, 1).float()\n",
    "    decoder_hidden = h_0_tgt\n",
    "    h_t_tilde, y_hats, indice = None, [], []\n",
    "    \n",
    "    ## Repeat a loop while sum of \"is_undone\" flag is bigger than 0\n",
    "    ## or current time-step is smaller than maximum length\n",
    "    \n",
    "    while is_undone.sum() > 0 and len(indice) < max_length:\n",
    "        \n",
    "        ## Unlike training procedure, take the last time-step's output during the inference.\n",
    "        ## |emb_t| = (batch_size, 1, word_vec_dim)\n",
    "        emb_t = self.emb_dec(y)\n",
    "        \n",
    "        decoder_output, decoder_hidden = self.decoder(emb_t, \n",
    "                                                      h_t_tilde, \n",
    "                                                      decoder_hidden)\n",
    "        \n",
    "        context_vector = self.attn(h_src, decoder_output, mask)\n",
    "        h_t_tilde = self.tanh(self.concat(torch.cat([decoder_output,\n",
    "                                                     context_vector], dim = -1)))\n",
    "        \n",
    "        ## |y_hat| = (batch_size, 1, output_size)\n",
    "        y_hat = self.generator(h_t_tilde)\n",
    "        \n",
    "        y_hats += [y_hat]\n",
    "        \n",
    "        if is_greedy:\n",
    "            y = torch.topk(y_hat, 1, dim = -1)[1].squeeze(-1)\n",
    "            \n",
    "        else:\n",
    "            ## Take a random sampling baed on the multinoulli distribution\n",
    "            y = torch.multinomial(y_hat.exp().view(batch_size,-1), 1)\n",
    "            \n",
    "        ## Put PAD if the sample is done\n",
    "        \n",
    "        ## |y| = (batch_size, 1)\n",
    "        ## |is_undone| = (batch_size, 1)\n",
    "        y = y.masked_fill_((1. - is_undone).byte(), data_loader.PAD)\n",
    "        is_undone = is_undone * torch.ne(y, data_loader.EOS).float()\n",
    "        \n",
    "        indice += [y]\n",
    "    \n",
    "    ## |y_hats| = (batch_size, length, output_size)\n",
    "    ## |indice| = (batch_size, length)\n",
    "    y_hats = torch.cat(y_hats, dim = 1)\n",
    "    indice = torch.cat(indice, dim = -1)\n",
    "    \n",
    "    return y_hats, indice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e64ab5",
   "metadata": {},
   "source": [
    "가끔 너무 어렵거나 훈련 데이터에서 볼 수 없었던 형태의 문장이 인코딩되어 들어오거나, 훈련 데이터가 적어서 디코더가 잘 훈련되어 있지 않으면, 같은 단어를 반복하며 끝이 없는 문장을 뱉어내는 현상이 발생할 수 있습니다. 즉, EOS가 나오지 않는 상황이 발생할 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "\n",
    "|정상|비정상|\n",
    "|---|----|\n",
    "|나는 학교에 갑니다.|나는 학교에 학교에 학교에 학교에 학교에 ...|\n",
    "\n",
    "<br></br>\n",
    "\n",
    "따라서 우리는 앞의 함수 입력에서 볼 수 있듯이, 최대 가능 문장 길이를 정해주어 끝이 없는 문장이 나오는 경우에 대비합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19cdbf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a0d67",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc0451",
   "metadata": {},
   "source": [
    "Greedy Search Algorithm은 매우 쉽고 간편하지만 최적의 해를 보장하지는 않습니다. 따라서 최적의 해에 더 가까워지기 위해 k개의 후보를 더 추적합니다. 이때 k를 **beam**이라고 부릅니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/10-6-4-beam.jpg)\n",
    "<br></br>\n",
    "\n",
    "현재 time-step에서 최고 누적 확률을 가진 인덱스의 단어 k개를 뽑은뒤 다음 time-step에 대해 k번 추론을 수행합니다. 그리고 총 k|V|개의 `softmax` 결과값 중 다시 최고 누적 확률 k개를 뽑아 다음 time-step으로 넘깁니다. 여기서 중요한 점은 다음과 같은 2가지입니다.\n",
    "\n",
    "1. 누적 확률을 사용하여 최고 순위 k개를 뽑습니다. 이때 보통 로그 확률을 사용하므로 현재 time-step까지의 로그 확률에 대한 합을 추적하고 있어야 합니다.\n",
    "2. 이전 time-step에서 뽑힌 k개에 대해 계산한 현재 time-step의 모든 결과물 중에서 최고 누적확률 k개를 다시 뽑습니다. 이전 time-step의 k개에 대해 각각 k개를 뽑는게 아닙니다.\n",
    "\n",
    "Beam Search를 사용하면 더 넓은 경로에 대해 탐색하므로 더 나은 성능을 보장합니다. 하지만 빔의 크기만큼 연산을 더 수행하므로 속도 저하가 일어납니다.\n",
    "\n",
    "다음은 빔서치의 성능 향상에 대한 실험 결과입니다.\n",
    "\n",
    "<br></br>\n",
    "\n",
    "|알고리즘|Valid set NLL (BLEU)|Test set NLL (BLEU)|\n",
    "|------|--------------------|-------------------|\n",
    "|샘플링|22.98 (15.64)|26.25 (16.76)|\n",
    "|Greedy|27.88 (15.50)|26.49 (16.66)|\n",
    "|Beam (k=5)|20.18 (17.03)|22.81 (18.56)|\n",
    "|Beam (k=10)|19.92 (17.13)|22.44 (18.59)|\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a09761",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701541e8",
   "metadata": {},
   "source": [
    "#### 구현 관점에서 바라보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2cdeb",
   "metadata": {},
   "source": [
    "앞에서 살펴본 그림은 하나의 샘플에 대해 추론을 수행하기 위한 빔서치를 나타낸 것입니다. 여기서 빔의 크기는 k = 3입니다. 보통 빔서치는 EOS가 k만큼 나올떄까지 수행됩니다. 즉 앞으로 우리가 다룰 예제에서는 3개 이상의 EOS가 출현하면 빔서치는 종료됩니다.\n",
    "\n",
    "앞에서 본 그림에서는 마지막 직전의 time-step에서 1개의 EOS가 발생했고, EOS에서 다시 이어지는 추론 대신 다른 2개의 추론중 최고 누적 확률 3개를 다시 선택하는 것을 볼 수 있습니다. 우리는 EOS 이후의 해당 빔의 누적 확률값을 0으로 주어 이것을 쉽게 구현할 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\text{Given}\\ X = x_1, x_2, \\dots, x_n, \\\\\n",
    "\\text{we need to find}\\ b^* \\\\\n",
    "\\text{where}\\ B_t = \\{ b_t^1, b_t^2, \\dots, b_t^K \\},b_t^i = \\{\\hat{y_1^i}, \\dots, \\hat{y_t^i}\\}\n",
    "$$ \n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\hat{y_i^k} = argmax_{y \\in Y}^k \\{log P_\\theta(y_t|X,b_{t-1}^1 + log P_\\theta(b_{t-1}^K|X), \\dots, log P_\\theta(y_t|X,b_{t-1}^1) + log P_\\theta(b_{t-1}^K|X) \\}\n",
    "$$ \n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "b_t^k = \\{ \\hat{y_1^k}, \\dots, \\hat{y_{t-1}^k} \\} + \\{\\hat{y_t^k}\\} \\\\\n",
    "= \\{ \\hat{y_1^k}, \\dots, \\hat{y_t^k}\\} \\\\\n",
    "= argmax_{b \\in B_t}^k \\{log P_\\theta(y_t|X,b_{t-1}^1 + log P_\\theta(b_{t-1}^K|X), \\dots, log P_\\theta(y_t|X,b_{t-1}^1) + log P_\\theta(b_{t-1}^K|X)\\} + \\{ \\hat{y_t^k} \\}\n",
    "$$ \n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "log P_\\theta(b_t^i|X) = log P_\\theta(y_t = \\hat{y_t^i}|X) + log P_\\theta(b_t^i|X) \\\\\n",
    "= \\sum_{t=1}^t log P_\\theta (y_t = \\hat{y_t^i}|X,\\hat{y_{<t}^i})\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "예를 들어 |V| = 30,000이고, k = 3이라고 가정하겠습니다. 그럼 소프트맥스 계층의 유닛 개수는 30,000개입니다. 따라서 한 time-step의 예측 결과의 개수는 |V| x k = 90,000이 됩니다. 이 9만개의 소프트맥스 계층 유닛 (vocabulary의 각 단어)의 각각의 확률값에, 이전 time-step에서 선택된 빔의 누적 확률값을 더해 최종 누적 확률값 9만개를 얻습니다. 여기서 총 90,000개의 누적 확률값중에서 최고의 k개를 뽑아 다음 time-step의 예측을 위한 디코더의 입력으로 사용합니다. 이때 반복하는 k번의 작업을 for반복문으로 해결할 수도 있지만, 미니배치 크기가 마치 k인 것처럼 미니 배치를 구성해서 seq2seq에 넣어주면 됩니다. 이것은 한개의 문장이 주어졌을때의 시나리오이고, 미니배치로 문장이 주어진다면 $batch size x |V| x k$가 될 것입니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/10-6-4-beamsearch.jpg)\n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "![](./images/10-6-4-minibatch.jpg)\n",
    "<br></br>\n",
    "\n",
    "seq2seq은 미니배치를 입력으로 받고 미니배치를 출력으로 반환합니다. 따라서 상황에 따라 필요한 입력들을 모아서 미니배치를 만들고, 그에 해달하는 출력을 비니배치로 받아 입력에 대해 필요한 출력을 나누어 가지면 됩니다. 아까 1개의 문장에 대해 설명할대, k번 반복하는 작업에 대해 for문을 사용하는 것 대신, 마치 미니배치 크기가 k개인 것처럼 미니배치를 만들어 병렬 연산을 통해 구현하는 것을 이야기 하였습니다. \n",
    "\n",
    "m개의 문장이 주어지는 미니배치 상황에서도 똑같습니다. 문장별로 k번 반복하는 작업이 있으므로, 결국 최종 임시 미니 배치 크기는 m x k가 될 것입니다. 우리는 매 time-step마다 각 m개의 문장별로 최고 누적 확률 k개의 입력을 뽑아내서 m x k 크기의 임시 미니배치를 구성하여 seq2seq에 입력으로 넣습니다. seq2seq가 m x k크기의 임시 미니배치를 출력으로 반환하면, 다시 m개의 문장별로 k개씩 확률 분포를 뽑아서, 최고 누적 확률을 계산하여 다음 time-step의 입력이 될것을 정하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619db6f3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc00efea",
   "metadata": {},
   "source": [
    "#### 빔서치 수행 결과 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff69d27",
   "metadata": {},
   "source": [
    "경험상 빔서치를 제대로 구현하면 BLEU 성능이 2가량 올라가는 것을 볼 수 있습니다. 다음은 빔의 크기 k = 1인 단순한 Greedy Search Algorithm과 k = 5인 빔서치의 결과를 비교한 예제입니다. 대체적으로 표현이 더 풍부해지는 것을 알 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "\n",
    "|번호|빔 크기 k = 1|빔 크기 k = 5|\n",
    "|---|------------|-----------|\n",
    "|1|너 스스로 말하고, 나를 위해 말하지마|당신 자신을 위해 말하세요, 당신을 나를 위해 말하지 않아요.|\n",
    "|2|걱정마. 난 그것에 익숙해|걱정마. 난 그것에 익숙해져 있어.|\n",
    "|3|너는 내 상사에게 말해야 한다.|너는 나의 상사에게 말해야 한다.|\n",
    "|4|그녀는 그와 결혼하지 않기로 결심한 것을 느꼈다.|그녀는 그와 결혼하지 않기로 결심한 그녀의 결심을 느꼈다.|\n",
    "|5|배달 채널을 삭제할 수 없습니다.|배달 채널이 삭제되지 않았습니다.|\n",
    "|6|하지만 여러모로 나는 행복한 사람이 나를 화나게 하지 않는다.|하지만 많은 면에서 나는 행복한 사람이 나를 화나게 하지 않는다.|\n",
    "|7|그 점원의 불의의 정중함은 나를 기분 좋게 만들었다.|그 점원의 예상치 못한 공손함이 나를 기분 좋게 만들었다.|\n",
    "|8|내가 너의 조종사를 보고 있는 것을 신경쓰지않기를 바란다.|내가 너의 조종사를 감시하는 것을 신경쓰지 않았으면 좋겠어|\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acbacb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d6a18",
   "metadata": {},
   "source": [
    "#### 길이 패널티"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892439d",
   "metadata": {},
   "source": [
    "앞의 탐색 알고리즘을 코딩하여 직접 실행시키면 문제점이 있습니다. 현재 time-step까지의 확률을 모두 곱하므로 문장이 길어질수록 확률이 낮아진다는 점입니다. 따라서 짧은 문장일수록 더 높은 점수를 획득하는 경향이 있습니다. 이러한 현상을 피하기 위해 예측한 문장의 길이에 따른 페널티를 주어 짧은 문장이 긴 문장을 제치고 선택되는 것을 방지합니다.\n",
    "\n",
    "길이 패널티의 수식은 다음과 같습니다. 이를 위해서는 추가적인 하이퍼 파라미터를 갖습니다. 보통 $\\alpha = 1.2, \\beta = 5$의 값을 갖습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "log \\tilde{P}(\\hat{Y}|X) = log P(\\hat{Y}|X) x penalty \\\\\n",
    "penalty = \\frac{(1+length)^\\alpha}{(1+\\beta)^\\alpha}\n",
    "$$\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394d9cc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e731c5",
   "metadata": {},
   "source": [
    "### 파이토치 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be4587f",
   "metadata": {},
   "source": [
    "#### SingleBeamSearchSpace 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afff70c",
   "metadata": {},
   "source": [
    "지금부터 살펴볼 코드는 하나의 문장에 대한 빔서치를 수행하기 위한 클래스입니다. 따라서 해당 클래스의 객체는 입력으로 주어진 미니배치의 크기 (문장의 개수)만큼 선언됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a271d5a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2378f0",
   "metadata": {},
   "source": [
    "##### 클래스 선언 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977e6894",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-041ad41813f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mLENGTH_PENALTY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import data_loader\n",
    "\n",
    "LENGTH_PENALTY = 1.2\n",
    "MIN_LENGTH = 5\n",
    "\n",
    "class SingleBeamSearchSpace():\n",
    "    \n",
    "    def __init__(self,\n",
    "                hidden,\n",
    "                h_t_tilde = None,\n",
    "                beam_size = 5,\n",
    "                max_length = 255):\n",
    "        \n",
    "        self.beam_size = beam_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        super(SingleBeamSearchSpace, self).__init__()\n",
    "        \n",
    "        ## To put data to the same device\n",
    "        self.device = hidden[0].device\n",
    "        \n",
    "        ## Inferred word index for each time-step.\n",
    "        ## For now, initialized with initial time-step\n",
    "        self.word_indice = [torch.LongTensor(beam_size).zero_().to(self.device) + data_loader.BOS]\n",
    "        \n",
    "        ## Index origin of current beam\n",
    "        self.prev_beam_indice = [torch.LongTensor(beam_size).zero_().to(self.device) - 1]\n",
    "\n",
    "        ## Cumulative log-prob for each beam\n",
    "        self.cumulative_probs = [torch.FloatTensor([.0] + [-float(\"inf\")] * (beam_size - 1)).to(self.device)]\n",
    "        \n",
    "        ## 1 if it is done else 0\n",
    "        self.masks = [torch.ByteTensor(beam_size).zero_().to(self.device)]\n",
    "        \n",
    "        ## We don't need to remember every time-step of hidden states:\n",
    "        ## prev_hidden, prev_cell, prev_h_t_tilde\n",
    "        ## we only need the last one\n",
    "        \n",
    "        ## |hidden[0]| = (n_layers, 1, hidden_size)\n",
    "        ## |prev_hidden| = (n_layers, beam_size, hidden_size)\n",
    "        self.prev_hidden = torch.cat([hidden[0]] * beam_size, dim = 1)\n",
    "        \n",
    "        ## |prev_cell| (n_layers, beam_size, hidden_size)\n",
    "        self.prev_cell = torch.cat([hidden[1]] * beam_size, dim = 1)\n",
    "        \n",
    "        ## |h_t_tilde| = (batch_size = 1, 1, hidden_size)\n",
    "        ## |prev_h_t_tilde| = (batch_size, 1, hidden_size)\n",
    "        self.prev_h_t_tilde = torch.cat([h_t_tilde] * beam_size, dim = 0) if h_t_tilde is not None else None\n",
    "        \n",
    "        self.current_time_step = 0\n",
    "        self.done_cnt = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a208375",
   "metadata": {},
   "source": [
    "##### 길이 패널티 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709d722b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LENGTH_PENALTY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5de5a429bd3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m def get_length_penalty(self,\n\u001b[1;32m      2\u001b[0m                        \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                        \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLENGTH_PENALTY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                        min_length = MIN_LENGTH):\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LENGTH_PENALTY' is not defined"
     ]
    }
   ],
   "source": [
    "def get_length_penalty(self,\n",
    "                       length,\n",
    "                       alpha = LENGTH_PENALTY,\n",
    "                       min_length = MIN_LENGTH):\n",
    "    \n",
    "    ## Calculate length -penalty\n",
    "    ## Because shorter sentence usually have bigger probability.\n",
    "    ## Thus we need to put penalty for shorter one\n",
    "    p = (1 + length) ** alpha / (1 + min_length) ** alpha\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb340ebc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf08e8",
   "metadata": {},
   "source": [
    "##### 디코딩 작업 종료 체크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09918bb",
   "metadata": {},
   "source": [
    "EOS가 한개씩 나타날때마다 self.done_cnt가 증가하므로, 빔의 크기 k보다 self.done_cnt가 크면 디코딩 작업이 종료됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08a1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_done(Self):\n",
    "    if self.done_cnt >= self.beam_size:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aed63a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb17da1",
   "metadata": {},
   "source": [
    "##### 가짜 미니배치의 일부 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8794a1",
   "metadata": {},
   "source": [
    "매 time-step마다 seq2seq에게 1개의 문장에 대한 k개의 입력이 주어져야 합니다. 배치크기가 m일때는 m개의 문장에 대해 각각 k개의 입력이 될 것입니다. 최종 미니배치의 크기는 m x k가 될것이므로 그 일부인 k개를 반환하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172c5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(self):\n",
    "    ## |y_hat| = (beam_size, 1)\n",
    "    y_hat = self.word_indice[-1].unsqueeze(-1)\n",
    "    \n",
    "    ## |hidden| = (n_layers, beam_size, hidden_size)\n",
    "    hidden = (self.prev_hidden, self.prev_cell)\n",
    "    \n",
    "    ## |h_t_tilde| = (beam_size, 1, hidden_size) or None\n",
    "    h_t_tilde = self.prev_h_t_tilde\n",
    "    \n",
    "    return y_hat, hidden, h_t_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66406214",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193da63",
   "metadata": {},
   "source": [
    "##### 최고 누적 확률 k개 고르기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fbdf1",
   "metadata": {},
   "source": [
    "매 time-step마다 k개의 결과값을 받아 이전 time-step으로부터의 빔서치 정보를 이용하여 누적확률을 계산하고, 최고 누적확률 k개를 뽑는 작업을 수행하는 함수입니다. self.mask의 값의 따라 이전에 EOS가 출현한 경우에는 직전 누적확률을 0으로 만들어 계산하는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa86ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_result(self, y_hat, hidden, h_t_tilde):\n",
    "    ## |y_hat| = (beam_size, 1, output_size)\n",
    "    ## |hidden| = (n_layers, beam_size, hidden_size)\n",
    "    ## |h_t_tilde| = (beam_size, 1, hidden_size)  \n",
    "    output_size = y_hat.size(-1)\n",
    "    \n",
    "    self.current_time_step += 1\n",
    "    \n",
    "    ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

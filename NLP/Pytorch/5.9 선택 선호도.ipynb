{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac50cb1c",
   "metadata": {},
   "source": [
    "**$선택\\ 선호도^{selectional\\ preference}$**라는 개념에 대해서 다루어보겠습니다.\n",
    "\n",
    "문장은 여러 단어의 시퀀스로 이루어집니다. 따라서 각 단어는 문장 내 주변의 단어들에 따라 그 의미가 정해지기 마련입니다.\n",
    "\n",
    "선택 선호도는 이를 더 수치화하여 나타냅니다. 예를 들어 \"마시다\"라는 동사에 대한 목적어는 \"음료\": 클래스에 소 ㄱ하는 단어가 올 확률이 높습니다. 따라서 우리는 \"차\"라는 단어가 \"음료\" 클래스에 속하는지 \"교통수단\" 클래스에 속하는지 쉽게 알 수 있습니다. 이런 성질을 이용하여 단어 중의성 해소를 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076dcfe",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9e595",
   "metadata": {},
   "source": [
    "### 선택 선호도 강도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b7ecc",
   "metadata": {},
   "source": [
    "선택 선호도는 단어와 단어 사이의 관계가 좀 더 특별한 경우를 수치화하여 나타냅니다. $술어\\ 동사^{predicate\\ verb}$가 주어졌을때, 목적어 관계에 있는 $표제어^{headword}$ 단어들의 분포는 평소 문서 내에 해당 명사가 나올 분포와 다를 것입니다. 그 분포의 차이가 크면 클수록 해당 술어는 더 강력한 선택 선호도를 갖는다고 할 수 있습니다. 이것을 **쿨백-라이블러 발산 (KLD)**을 사용하여 정의했습니다.\n",
    "\n",
    "<br></br>\n",
    "$$S_R(w)=KL(P(C|w)||P(C)) \\\\\n",
    "= -\\sum_{c \\in C}P(c|w) log\\frac{P(c)}{P(c|w)} \\\\\n",
    "= -\\mathbb{E}_{C \\sim P(C|w)}[log\\frac{P(C)}{P(C|W=w)}] $$\n",
    "<br></br>\n",
    "\n",
    "이 수식을 해석하면, 선택 선호도 강도 $S_R(w)$는 w가 주어졌을때의 오브젝트 클래스 C의 분포 P(C|w)와 그냥 해당 클래스들의 사전 분포 P(C)와의 KLD로 정의되어 있음을 알 수 있습니다. 즉, 선택 선호도 강도는 술어가 표제어로 특정 클래스를 얼마나 선택적으로 선호하는지에 대한 수치입니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/5-9-1-selectional.jpg)\n",
    "<br></br>\n",
    "\n",
    "예를 들어 \"음식\" 클래스의 단어는 \"공구\" 클래스의 단어보다 나타날 확률이 훨씬 높을 것입니다. 이때 \"사용하다\"라는 동사 술어가 주어진다면, 동사-목적어 관계에 있는 표제어로서의 \"음식\" 클래스의 확률은 \"공구\" 클래스의 확률보다 낮아질 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981742c8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a599d8",
   "metadata": {},
   "source": [
    "### 선택 관련도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87265508",
   "metadata": {},
   "source": [
    "술어와 특정 클래스 사이의 $선택\\ 관련도^{selectional\\ association}$를 어떻게 나타내는지 살펴보겠습니다. 선택관련도 $A_R(w,c)는 다음과 같이 표현됩니다.\n",
    "\n",
    "<br></br>\n",
    "$$A_R(w,c) = -\\frac{P(c|w)log\\frac{P(c)}{P(c|w)}}{S_R(w)}$$\n",
    "<br></br>\n",
    "\n",
    "선택 선호도 강도가 낮은 술어에 대해서 윗변의 값이 클 경우에는 술어와 클래스 사이에 더 큰 선택 관련도를 갖는다고 정의합니다. 즉, 선택 선호도 강도가 낮아서, 해당 술어는 클래스에 대한 선택적 선호 강도가 낮음에도 불구하고, 특정 클래스만 유독 술어에 영향을 받아서 윗변이 커질수록 선택 관련도의 수치도 커집니다.\n",
    "\n",
    "예를 들어 어떤 매우 일반적인 동사에 대해서는 대부분의 클래스가 사전 확률 분포와 여전히 비슷하게 나타날 것입니다. 따라서 선택 선호도 강도 $S_R(w)$는 0에 가까울 것입니다. 하지만 그중 해당 동사와 붙어서 자주 출현하는 클래스의 목적어가 있다면 선택 관련도 $A_R(w,c)$는 매우 높게 나타날 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e54304",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2a8a5",
   "metadata": {},
   "source": [
    "### 선택 선호도와 WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7d62b",
   "metadata": {},
   "source": [
    "이런 선택 선호도의 특징을 이용하여 단어 중의성 해소(WSD)에 활용할 수 있습니다. \"마시다\"라는 동사에 \"차\"라는 목적어가 함께 있을때, 선택 선호도를 통해서 \"차\"는 \"음료\"클래스 속한다고 말할 수 있을 것입니다.\n",
    "\n",
    "문제는 \"차\"가 \"교통수단\"또는 \"음료\"클래스에 속하는 것을 알아내는 것입니다. 우리가 가지고 있는 코퍼스는 단어들로 표현되어 있을뿐, 클래스로 표현되어 있지 않습니다. 만약 단어가 어떤 클래스에 속하는지 미리 알고 있다면 단어들의 출현 빈도를 세어 클래스의 확률 분포를 추정할 수 있을 것입니다. 결국 이를 위해서는 사전에 정의된 지식 또는 데이터셋이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db8320",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da7eae",
   "metadata": {},
   "source": [
    "### 워드넷 기반의 선택 선호도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18a98b",
   "metadata": {},
   "source": [
    "우리는 워드넷을 통해 \"차(car)\"의 상위어를 알 수 있고, 이 것을 클래스로 삼아 필요한 정보들을 얻을 수 있습니다. 영어 워드넷에서 \"eat\"뒤에 있는 \"bass\"의 상위어를 통해 먹는 물고기 \"bass\"인지 아니면 악기 \"bass\"인지 구분할 수 있습니다.\n",
    "\n",
    "술어와 클래스 사이의 확률 분포를 정의하는 출현 빈도의 계산 수식은 다음과 같습니다.\n",
    "\n",
    "<br></br>\n",
    "$$Count_R(w,c) = \\sum_{h \\in c}\\frac{Count_R(w,h)}{|Classes(h)|}$$\n",
    "<br></br>\n",
    "\n",
    "클래스 c에 속하는 $표제어^{headword}$, 즉 h는 실제 코퍼스에 나타난 단어로, 술어 w와 함께 출현한 h의 빈도를 세고, h가 속한 클래스들의 잡힙의 크기인 |Classes(h)|로 나누어 줍니다. 그리고 이를 클래스 c에 속하는 모든 표제어에 대해 수행한 후, 이를 합한 값은 $Count_R(w,c)$를 근사합니다.\n",
    "\n",
    "<br></br>\n",
    "$$\\hat{c} = argmax_{c \\in C}A_R(w,c)$$\n",
    "<br></br>\n",
    "\n",
    "이를 통해 우리는 술어 w와 표제어 h가 주어졌을때 h의 클래스 c를 추정한 $\\hat{c}$를 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2cf1d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178f141",
   "metadata": {},
   "source": [
    "### 유사어휘를 통한 선택 선호도 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ad7d8",
   "metadata": {},
   "source": [
    "선택 선호도는 어떻게 평가할 수 있을까요? 정교한 데이터셋을 설계하고 만들어서 선택 선호도의 성능을 평가할 수 도 있지만, 더 쉽고 보편적으로 적용할 수 있는 방법은 없을까요?\n",
    "\n",
    "$유사\\ 어휘^{pseudo\\ word}$가 하나의 해답이 될 수도 있습니다. 유사어휘는 2개의 단어가 인위적으로 합성되어 만들어진 단어를 말합니다. 예를 들어 \"banana\"와 \"door\"를 합쳐 \"banana-door\"이라는 유사어휘를 만들어 낼 수 있습니다. 이 \"banana-door\"라는 단어는 실생활에서 쓰일리 없는 단어입니다. 하지만 우리는 이 단어가 \"eat\"이나 \"open\"이라는 동사 술어와 함께 목적어 표제어로써 나타났을때, \"eat\"에 대해서는 \"banana\", \"open\"에 대해서는 \"door\"를 선택하도록 해야 올바른 선택 선호도 알고리즘을 구현했음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a997e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed0234",
   "metadata": {},
   "source": [
    "### 유사도 기반의 선택 선호도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f879b",
   "metadata": {},
   "source": [
    "워드넷과 같은 시소러스에 의존하지 않고 선택 선호도를 구할 수 있다면 좋을 것입니다.\n",
    "\n",
    "단어간 유사도를 통해 시소러스에 의존하지않고 데이터를 기반으로 간단하게 선택 선호도를 구하는 방법이 제시되었습니다\n",
    "\n",
    "<br></br>\n",
    "$$(w,h,r)$$\n",
    "\n",
    "where R is a relationship, such as a verb-object.\n",
    "<br></br>\n",
    "\n",
    "술어 w와 표제어 h, 그리고 두 단어 사이의 관계 R이 튜플로 주어집니다. 이때 선택 관련도 $A_R(w, h_0)$는 다음과 같이 정의할 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "$$A_R(w,h_0) = \\sum_{h \\in Seen_R(w)}sim(h_0,h)\\phi_R(w,h)$$\n",
    "<br></br>\n",
    "\n",
    "이때 가중치 $\\phi_R(w,h)$는 동등하게 1로 주어도 되고, 다음과 같이 IDF를 사용하여 정의할 수도 있습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\\phi_R(w,h) = IDF(h)$$\n",
    "<br></br>\n",
    "\n",
    "또한 sim 함수는 이전에 다루었던 코사인 유사도 또는 자카드 유사도를 포함하여 다양한 유사도 함수를 사용할 수 있습니다.\n",
    "\n",
    "지금 다루는 $A_R(w, h_0)$는 선호하는 클래스를 알아내는 것이 아닌, \"유사어휘와 같이 2개의 단어가 주어졌을때\" 선호하는 단어를 고르는 문제로 만들었습니다.\n",
    "\n",
    "이 방법은 시소러스 없이도 쉽게 선택 선호도를 계산할 수 있게합니다. 하지만 유사도를 비교하기 위해 $Seen_R(W)$ 함수를 통해 대상 단어를 선정하기 떄문에, 코퍼스에 따라 유사도를 구할 수 있는 대상이 달라집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa376cf1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919ab6a",
   "metadata": {},
   "source": [
    "### 유사도 기반의 선택 선호도 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85721818",
   "metadata": {},
   "source": [
    "앞에 설명한 방법을 파이썬으로 구현한 예제를 살펴보겠습니다.\n",
    "\n",
    "코퍼스를 받아 문장내에서 술어 (동사, VV)와 표제어 (명사, NNG)를 찾아 $Seen_R(w)$ 함수를 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6c80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "def count_seen_headwords(lines, predicatve = \"VV\", headword = \"NNG\"):\n",
    "    tagger = Kkma()\n",
    "    seen_dict = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        pos_result = tagger.pos(line)\n",
    "        \n",
    "        word_h = None\n",
    "        word_p = None\n",
    "        \n",
    "        for word, pos in pos_result:\n",
    "            if pos == predicatve or pos[:3] == predicatve + \"+\":\n",
    "                word_p = word\n",
    "                break\n",
    "                \n",
    "            if pos == headword:\n",
    "                word_h = word\n",
    "            \n",
    "        if word_h is not None and word_p is not None:\n",
    "            seen_dict[word_p] = [word_h] + ([] if seend_dict.get(word_p) is None else seen_dict[word_p])\n",
    "    \n",
    "    return seen_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed472d7b",
   "metadata": {},
   "source": [
    "주어진 술어와 표제어에 대해서 선택 관련도 점수를 구하는 함수를 다음과 같이 구현할 수 있습니다. 단어 사이의 유사도 $sim(h_0,h)$를 구하기 위해, 이전에 구성한 특정 벡터들을 담은 Pandas Dataframe을 받습니다. 그럼 **metric**으로 주어진 함수를 통해 유사도를 계산합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db50d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def get_selectional_association(predicate, headword, lines, dataframe, metric):\n",
    "    v1 = torch.FloatTensornsor(dataframe.loc[headword].values)\n",
    "    seens = seen_headwords[predicate]\n",
    "    \n",
    "    total = 0\n",
    "    for seen in seens:\n",
    "        try:\n",
    "            v2 = torch.FloatTensor(dataframe.loc[seen].values)\n",
    "            total += metric(v1,v2)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223372c",
   "metadata": {},
   "source": [
    "앞의 함수들을 활용하여 주어진 술어에 대해서 올바른 headword를 고르는 wsd 함수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0dbd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsd(predicate, headwords):\n",
    "    selectional_associations = []\n",
    "    \n",
    "    for h in headwords:\n",
    "        selectional_associations += [get_selectional_association(predicate,\n",
    "                                                                 h,\n",
    "                                                                 lines,\n",
    "                                                                 co,\n",
    "                                                                 get_cosine_similarity)]\n",
    "        \n",
    "    print(selectional_associations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53fddc",
   "metadata": {},
   "source": [
    "실제로 wsd 함수에 대해 \"피우\"라는 동사가 주어졌을때 \"담배\", \"맥주\", \"사과\"중에서 어떤 단어를 선택하는지 살펴본 결과는 다음과 같습니다.\n",
    "\n",
    "<br></br>\n",
    "```python\n",
    ">>> wsd(\"피우\", [\"담배\",\"맥주\",\"사과\"])\n",
    "[tensor(6.1853), tensor(3.9723), tensor(3.8503)]\n",
    "```\n",
    "<br></br>\n",
    "\n",
    "기특하게도 \"담배\"가 예상대로 잘 선택됨을 알 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be3a4be",
   "metadata": {},
   "source": [
    "RNN은 가변길이의 시퀀설 데이터 형태 입력에는 훌륭하게 동작하지만, 그 길이가 길어지면 앞서 입력된 데이터를 잊어버리는 치명적인 단점이 있습니다. 이를 보완하기 위해 만들어진 것이 **LSTM**입니다.\n",
    "\n",
    "LSTM은 기존 RNN의 은닉 상태 이외에도 별도의 **cell state**라는 변수를 두어 그 기억력을 증가시킵니다. 그뿐만 아니라 여러가지 **gate**를 둠으로써 기억하거나, 잊어버리거나, 출력하고자 하는 데이터의 양을 상황에 따라 마치 수도꼭지를 잠갔다가 열듯이 효과적으로 제어합니다. 그 결과 긴 길이의 데이터에 대해서도 효율적으로 대처할 수 있습니다\n",
    "\n",
    "이때문에 LSTM의 수식은 RNN에 비해 복잡해집니다. 더 많아진 파라미터들을 훈련시키려면 상대적으로 더 많은 데이터를 이용해 더 오래 훈련해야 합니다. 다음은 LSTM의 수식입니다.\n",
    "\n",
    "<br></br>\n",
    "$$i_t = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi}) \\\\ \n",
    "f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf}) \\\\\n",
    "g_t = tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg}) \\\\\n",
    "o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho}) \\\\\n",
    "c_t = f_tc_{t-1} + i_t g_t \\\\\n",
    "h_t = o_ttanh(c_t) $$\n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "![](./images/7-3-1-lstm.jpg)\n",
    "<br></br>\n",
    "\n",
    "각 게이트 앞에는 Sigmoid $\\sigma$가 붙어 0에서 1사이의 값으로 얼마나 게이트를 열고 닫을지 결정합니다. 그럼 그 결정된 값에 따라서 cell state $c_{t-1}$와 $g_t, c_t$가 새롭게 인코딩됩니다.\n",
    "\n",
    "RNN과 마찬가지로 LSTM 또한 여러 층으로 쌓거나 양방향으로 구현할 수 있습니다. 더 길어진 길이에 대해서도 RNN보다 훨씬 훌륭하게 대처하지만, 무한정 길어지는 길이에 대처할 수 있는 것은 아닙니다. 따라서 여전히 긴 길이의 데이터에 대해 효과적으로 기억하지 못한다는 문제점은 남아 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b949a5",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

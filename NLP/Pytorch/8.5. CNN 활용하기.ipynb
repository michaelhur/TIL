{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02980ad",
   "metadata": {},
   "source": [
    "CNN을 활용한 텍스트 분류 방법을 다룹니다. 이전까지 딥러닝을 이용한 자연어 처리는 RNN에 국한된 느낌이 매우 강했습니다. 텍스트 문장은 여러 단어로 이루어지고, 그 길이가 문장마다 상이하며, 문장 내 단어들은 같은 문장내의 단어에 따라서 영향받기 때문입니다. 더 비약적으로 표현하자면 time-step t에 등장하는 단어 $w_t$는 이전 time-step에 등장한 단어들 $w_1, \\dots, w_{t-1}$에 의존하기 때문입니다.\n",
    "\n",
    "순서 개념이 도입되어야 하기 때문에 RNN의 사용은 불가피하다고 여겨졌습니다. 한 논문의 CNN을 활용한 방법을 처음으로 소개하면서 새로운 시각이 열렸습니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-1-cnn.jpg)\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8791ba",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc5fdb",
   "metadata": {},
   "source": [
    "### 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563359c",
   "metadata": {},
   "source": [
    "CNN은 영상 처리 분야에서 매우 큰 성과를 거두고 있습니다. CNN의 목적 자체가, 기존의 전통적인 영상처리에서 사용되던 각종 합성곱 필터의 자동 구성을 위한 학습이기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d0a47",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e64c58",
   "metadata": {},
   "source": [
    "#### 합성곱 필터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb121f",
   "metadata": {},
   "source": [
    "전통적인 영상 처리 분야에서는 손으로 한땀 한땀 만들어낸 필터를 사용하여 $윤각선^{edge}$을 검출하는 등의 전처리 과정을 거치고, 거시거 얻어낸 특징을 통해 $객체\\ 탐지^{object\\ detection}$등을 구현하고 했습니다. 예를 들어 주어진 이미지에서 윤곽선을 찾기 위한 합성곱 필터는 다음과 같습니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-1-filter.jpg)\n",
    "<br></br>\n",
    "\n",
    "이 필터를 이미지에 적용하기 전과 후의 모습은 다음과 같습니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-1-output.jpg)\n",
    "<br></br>\n",
    "\n",
    "이처럼 딥러닝 이전의 영상 처리의 경우에는, 전처리 모듈에서 해결하고자하는 문제에 따라 여러 필터를 직접 적용하여 특징들을 얻어낸 후, 다음 단계의 모듈을 적용하여 문제를 해결하는 방식이였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c262b2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77587527",
   "metadata": {},
   "source": [
    "### 합성곱 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b63fb",
   "metadata": {},
   "source": [
    "만약 문제별로 필요한 합성곱 필터를 자동으로 찾아준다면 어떻게 될까요? CNN이 그런 역할을 합니다. 합성곱 연산을 통해 피드포워드된 값에 역전파를 수행하여 더 나은 합성곱 필터 값을 찾아나갑니다. MLE를 통한 최적화가 수행된 후에는 해당 데이터셋의 특징을 잘 추출하는 여러 종류의 합성곱 필터를 찾아낼 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-2-op.jpg)\n",
    "<br></br>\n",
    "\n",
    "합성곱 필터 연산의 피드포워드 연산은 다음과 같습니다. 필터가 주어진 이미지에서 차례로 합성곱 연산을 수행합니다. 상당히 많은 연산이 병렬로 수행됨을 알 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "y_{1,1} = Convolution(x_{1,1}, \\dots, x_{3,3}, \\theta)\\ \\text{where}\\ \\theta = \\{k_{1,1},\\dots,k_{3,3}\\} \\\\\n",
    "= x_{1,1} * k_{1,1} + \\dots + x_{3,3}*k_{3,3} \\\\\n",
    "= \\sum_{i=1}^3\\sum_{j=1}^3x_{i,j}*k_{i,j}\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "기본적으로 합성곱 연산의 결과물은 필터의 크기에 따라 입력보다 크기가 줄어듭니다. 앞의 그림에서도 필터가 3x3이므로, 6x6 입력에 적용하면 4x4 크기의 결과물을 얻을 수 있습니다. 입력과 같은 크기를 유지하고자 한다면 결과물의 바깥에 패딩을 추가할 수 있습니다. 즉, 입력 차원의 크기와 필터의 크기가 주어졌을때, 출력 차원의 크기는 다음과 같이 계산할 수 있습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\text{output_size = input_size - filter_size + 1}\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "이처럼 CNN은 패턴을 감지하는 필터를 자동으로 최적화함으로써 영상 처리 등의 분야에서 빼놓을 수 없는 중요한 역할을 담당합니다. 또한 이미지뿐만 아니라 음성 분야에서도 효과를 보고 있습니다. 음성 또는 오디오 신호의 경우 $Fourier Transform$을 통해 2차원의 시계열 데이터를 얻을 수 있는데, 그러한 데이터에서도 마찬가지로 패턴을 찾아내는 합성곱 연산이 매우 유요합니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-2-sound.jpg)\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca434e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec72614",
   "metadata": {},
   "source": [
    "### 텍스트 분류에 CNN 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d73949",
   "metadata": {},
   "source": [
    "그렇다면 텍스트 분류 과정에는 CNN을 어떻게 적용할까요?\n",
    "\n",
    "먼저 원핫 벡터를 표현하는 인데스 값을 단어 임베딩 벡터로 변환하면 1차원 벡터가 됩니다. 그리고 문장 내의 모든 time-step의 단어 임베딩 벡터를 합치면 2차원의 행렬이 됩니다. 이때 합성곱 연산을 수행하면 이제 텍스트에서도 CNN이 효과적으로 발휘됩니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-3-cnn.jpg)\n",
    "<br></br>\n",
    "\n",
    "각 텐서별 크기에서 맨 앞에 미니배치를 위한 차원을 추가하면 실제 구현에서의 텐서 크기가 됩니다.\n",
    "\n",
    "필터들은 우리가 배워야하는 신경망 가중치 파라미터이므로 $\\theta$로 표현합니다. 그리고 input은 RNN의 경우와 마찬가지로 임베딩 계층을 거친 결과값이라고 가정합니다. 따라서 n개의 문장이 각각 m개의 time-step을 가지고 있고, 각 time-step은 문장 내 단어로 d차원의 벡터로 표현합니다. 여기에 각 합성곱 연산을 위한 필터는 찾고자 하는 w개의 단어에 대한 패턴을 찾기위한 d차원의 w x d 크기를 갖습니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\text{cnn_out = CNN(input,\\theta)} \\\\\n",
    "|input| = (n,m,d) = (n, 1, m, d) \\\\\n",
    "|\\theta| = (\\#\\ filters, w, d) \\\\\n",
    "|cnn\\ out| = (n,\\#\\ filters, m - w + 1, d - d + 1) \\\\\n",
    "\\text{where n = batch_size} \\\\\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "이처럼 우리는 정해진 길이 w의 단어 조합 패턴을 검사할 수 있습니다. 이때 w를 1개가 아니라 여러개로 다양하게 설정하면, 다양한 길이의 단어 조합 패턴을 찾아낼 수 있습니다. \n",
    "\n",
    "CNN 계층의 결과값은 필터별 점수라고 볼 수 있습니다. 즉, 필터가 각각의 특징을 나타낸다고 봤을때, 각 특징별 점수가 될 것입니다. 따라서 우리는 문장내에서 각 특징 또는 원하는 단어 조합 패턴이 나타나는지 확인해야합니다. 이를 위해 이전 단계에서 구한 $\\text{cnn_out}$을 max pooling하여 문장당 각 특징에 대한 최고 점수를 구합니다. 맥스 풀링 계층은 특징별 최고 점수를 뽑아주시만, 이 과정에서 가변 길이의 $\\text{cnn_out}$을 고정 길이로 바꿔주는 역할도 합니다. 맥스 풀링 계층의 결과는 문장의 임베딩 벡터가 되는데, 이 벡터의 크기는 특징의 개수와 같습니다.\n",
    "\n",
    "<br></br>\n",
    "![](./images/8-5-3-cnnarch.jpg)\n",
    "<br></br>\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\text{cnn_out}_i = CNN(input,\\theta_i) \\\\\n",
    "\\text{where}\\ |\\theta_i| = (\\# filters, w_i, d), w_i \\in \\{w_1, w_2, \\dots, w_h\\} \\\\\n",
    "\\text{pool_out}_i = max_pooling(\\text{cnn_out}_i) \\\\\n",
    "|\\text{pool_out}_i| = (n, \\# filters) \\\\\n",
    "\\text{pool_out} = [poolout_1;poolout_2;\\dots;poolout_h] \\\\\n",
    "|\\text{pool_out}| = (n, h\\ x\\ \\# filters) \n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "이렇게 얻어진 문장별 임베딩 벡터에서 `softmax` 함수를 통해, 클래스별 확률값을 가진 불연속적인 확률 분포를 반환하면 분류를 위한 피드포워드가 끝납니다.\n",
    "\n",
    "<br></br>\n",
    "$$\n",
    "\\hat{y} = softmax(\\text{pool_out}W+b) \\\\\n",
    "\\text{where}\\ W \\in R^{(h\\ x\\ \\#\\ filters) x |C|}, b \\in R^{|C|}\n",
    "\\\\\n",
    "|\\hat{y}| = (n,|C|) \\\\\n",
    "\\text{where}\\ \\hat{y} = P(y|x)\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "여기에 RNN을 활용한 텍스트 분류때와 마찬가지로 교차 엔트로피 손실 함수를 적용하여, 이를 최소화하도록 최적화를 수행하면 CNN 신경망 또한 훈련될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed9039",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268f7b9",
   "metadata": {},
   "source": [
    "CNN을 이용한 텍스트 분류에 관란 더 직접적인 예를 들어보겠습니다. 특정 문장에 대해 긍정/ 부정 분류를 하는 문제가 있다고 가정합니다. 문장은 여러 단어로 이루어져 있고, 각 단어는 임베딩 계층을 통해 단어 임베딩 벡터로 변환된 상태입니다. 각 단어의 임베딩 벡터는 비슷한 의미를 가진 단어일수록 비슷한 값의 벡터값을 가집니다. 예를 들어 \"good\"이라는 던어는 그에 해당하는 임베딩 벡터로 구성될 것입니다. 그리고 \"better\", \"best\", \"great\"등의 단어들도 \"good\"과 비슷한 벡터값을 가질 것입니다. 이때 쉽게 예상할 수 있듯이 \"good\"은 긍정/ 부정 분류에 있어서 긍정을 나타내는 매우 중요한 신호로 작용할 것입니다.\n",
    "\n",
    "그렇다면 \"good\"에 해당하는 임베딩 벡터의 패턴을 감지하는 필터를 가진다면 \"good\"뿐만 아니라 \"better\", \"best\"등의 단어들도 함께 감지할 수 있을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ba565",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c1a60",
   "metadata": {},
   "source": [
    "### 파이토치 구현 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa41b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 word_vec_dim,\n",
    "                 n_classes,\n",
    "                 dropout_p = 0.5,\n",
    "                 window_sizes = [3, 4, 5],\n",
    "                 n_filters = [100, 100, 100]):\n",
    "        \n",
    "        ## Vocabulary Size\n",
    "        self.input_size = input_size\n",
    "        self.word_vec_dim = word_vec_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        ## window_size means that how many words a pattern covers\n",
    "        self.window_sizes = window_sizes\n",
    "        \n",
    "        ## n_filters means how many patterns to cover\n",
    "        self.n_filters = n_filters\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_dim)\n",
    "        \n",
    "        ## Since number of convolution layers would vary depend on len(window_sizes),\n",
    "        ## we use \"setattr\" and \"getattr\" methods to add layers to nn.Module object.\n",
    "        for window_size, n_filters in zip(window_sizes, n_filters):\n",
    "            cnn = nn.Conv2d(in_channels = 1,\n",
    "                            out_channels = n_filter,\n",
    "                            kernel_size = (window_size, word_vec_dim))\n",
    "            setattr(self, \"cnn-%d-%d\" % (window_size, n_filter), cnn)\n",
    "            \n",
    "        ## Becuase below layers are just operations,\n",
    "        ## it does not have learnable parameters.\n",
    "        ## So we just declare once\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        ## An input of generator layer is max values from each filter\n",
    "        self.generator = nn.Linear(sum(n_filters), n_classes)\n",
    "        \n",
    "        ## We use LogSoftmax + NLLLoss instead of Softmax and CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ## |x| = (batch_size, length)\n",
    "        x = self.emb(X)\n",
    "        \n",
    "        ## |x| = (batch_size, length, word_vec_dim)\n",
    "        min_length = max(self.window_sizes)\n",
    "        \n",
    "        if min_length > x.size(1):\n",
    "            ## Because some input is not long enough for maximum length of window size,\n",
    "            ## we add zero tensor for padding\n",
    "            \n",
    "            ## |pad| = (batch_size, min_length  - length, word_vec_dim)\n",
    "            pad = x.new(x.size(0), min_length - x.size(1), self.word_vec_dim).zero_()\n",
    "            \n",
    "            ## |x| = (batch_size, min_length, word_vec_dim)\n",
    "            x = torch.cat([x, pad], dim = 1)\n",
    "            \n",
    "        ## In ordinary case of vision task, you may have 3 channels on tensor,\n",
    "        ## But in this case, you would hvae just 1 channel,\n",
    "        ## which is added by \"unsqueeze\" method in below:\n",
    "        ## |x| = (batch_size, 1, length, word_vec_dim)\n",
    "        x = x.unsqueeze()\n",
    "        \n",
    "        cnn_outs = []\n",
    "        \n",
    "        for window_size, n_filter in zip(self.window_sizes, self.n_filters):\n",
    "            cnn = getattr(self, \"cnn-%d-%d\" % (window_size, n_filter))\n",
    "            cnn_out = self.dropout(self.relu(cnn(x)))\n",
    "            \n",
    "            ## |x| = (batch_size, n_filter, length - window_size + 1, 1)\n",
    "            \n",
    "            ## In case of max pooling, we does not know the pooling size,\n",
    "            ## because it depends on the length of the sentence\n",
    "            ## Therefore, we use instant function using \"nn.functional\" package.\n",
    "            \n",
    "            ## |cnn_out| = (batch_size, n_filter)\n",
    "            cnn_out = nn.functional.max_pool1d(input = cnn_out.squeeze(-1),\n",
    "                                               kernel_size = cnn_out.size(-2)).squeeze(-1)\n",
    "            \n",
    "            cnn_outs += [cnn_out]\n",
    "            \n",
    "            ## Merge output tensors from each convolution layer\n",
    "            ## |cnn_outs| = (batch_size, sum(n_filters))\n",
    "            cnn_outs = torch.cat(cnn_outs, dim = -1)\n",
    "            \n",
    "            ## |y| = (batch_size, n_classes)\n",
    "            y = self.activation(self.generator(cnn_outs))\n",
    "            \n",
    "            return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1054ecf",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
